{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Preprocessing.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"j1avPkgeKd7r","colab_type":"code","colab":{}},"source":["import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","import os\n","import shutil\n","import pickle\n","from google.colab import drive, files\n","import pandas as pd\n","import librosa\n","import librosa.display\n","import IPython.display as ipd\n","\n","import torch \n","import torch.nn as nn\n","from torch import optim"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4TB23wxTZne","colab_type":"code","colab":{}},"source":["fs = 44100\n","composers = ['Schubert', 'Beethoven', 'Brahms', 'Mozart', 'Bach']\n","split_duration = 20\n","save_path = 'spectogram/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Aii3KhgKjsm","colab_type":"code","colab":{}},"source":["!wget https://homes.cs.washington.edu/~thickstn/media/musicnet.npz\n","!wget https://homes.cs.washington.edu/~thickstn/media/musicnet_metadata.csv\n","!sudo apt-get install sox libsox-dev libsox-fmt-all\n","!pip install git+git://github.com/pytorch/audio"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HqikWAUkLN7i","colab_type":"code","colab":{}},"source":["with open('musicnet.npz', 'rb') as npz:\n","  musicnet_dataset = np.load('musicnet.npz', encoding = 'latin1', allow_pickle=True)\n","\n","musicnet_metadata = pd.read_csv('musicnet_metadata.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QaK1p7UcMLXZ","colab_type":"code","colab":{}},"source":["metadata = {}\n","musicnet_metadata = pd.read_csv('musicnet_metadata.csv')\n","for composer in composers:\n","  metadata[composer] = musicnet_metadata.loc[musicnet_metadata.composer == composer]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f-n8WX78227y","colab_type":"code","colab":{}},"source":["musicnet_metadata = pd.read_csv('musicnet_metadata.csv')\n","musicnet_metadata.loc[musicnet_metadata.composer == 'Schubert']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pLNAHk0TMkSM","colab_type":"code","colab":{}},"source":["sound, _ = dataset['1788']\n","ipd.Audio(sound[0:20*fs], rate=fs)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mA6XJD_0Qac8","colab_type":"code","colab":{}},"source":["spec = librosa.feature.melspectrogram(y=sound, \\\n","                                      sr=fs, \\\n",")\n","\n","plt.figure(figsize=(10, 4))\n","S_dB = librosa.power_to_db(spec, ref=np.max)\n","librosa.display.specshow(S_dB, x_axis='time', \\\n","                          y_axis='mel', sr=fs, \\\n","                          fmax=8000)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"48pjRmQDQtBh","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(10, 4))\n","S_dB = librosa.power_to_db(spec, ref=np.max)\n","librosa.display.specshow(S_dB, x_axis='time', y_axis='mel', sr=fs, fmax=8000)\n","plt.colorbar(format='%+2.0f dB')\n","plt.title('Mel-frequency spectrogram')\n","plt.tight_layout()\n","plt.show()\n","plt.axis('off')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t-g12jqWTsee","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(10, 4))\n","import matplotlib\n","matplotlib.use('Agg')\n","a = librosa.display.specshow(S_dB, x_axis='time', y_axis='mel', sr=fs)\n","plt.axis('off')\n","plt.savefig('deneme1.png', transparent = True, format = 'png')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gIIbFAyvWL4k","colab_type":"code","colab":{}},"source":["if os.path.isdir(save_path):\n","  shutil.rmtree(save_path)\n","  os.mkdir(save_path)\n","else:\n","  os.mkdir(save_path)\n","\n","for composer in composers:\n","  composerFolder = save_path+composer\n","  os.mkdir(composerFolder)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sEq5RnSQWlzH","colab_type":"code","colab":{}},"source":["for composer in composers:\n","  composerMetadata = metadata[composer]\n","  composerPath = save_path + composer + '/'\n","  count = 0\n","  for row in composerMetadata.itertuples():\n","    print(row.Index)\n","    id = str(row.id)\n","    duration = row.seconds\n","    sound, _ = musicnet_dataset[id]\n","    n_splits = np.floor(duration/split_duration).astype('int64')\n","    for i in range(n_splits):\n","      start = i*fs\n","      end = (i+1)*fs\n","      split = sound[start:end]\n","      spectogram = librosa.feature.melspectrogram(y=split, \\\n","                                        sr=fs, \\\n","                  )\n","      plt.figure(figsize=(10, 4))\n","      S_dB = librosa.power_to_db(spec, ref=np.max)\n","      librosa.display.specshow(S_dB, x_axis='time', \\\n","                                y_axis='mel', sr=fs)\n","      \n","      plt.savefig('{}.png'.format(count), format = 'png', transparent = True)\n","\n","\n","print(row)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2uAw__Y-WqcG","colab_type":"code","colab":{}},"source":["musicnet_metadata"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fYO9gc66W6fR","colab_type":"code","colab":{}},"source":["sound, _ = musicnet_dataset['1727']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jZqpW0YCZh-t","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CchYfbevZufk","colab_type":"code","colab":{}},"source":["from torchaudio.transforms import MelSpectrogram\n","spec =       MelSpectrogram(\\\n","                      n_fft=400, \\\n","                      win_length=None, \\\n","                      hop_length=None, \\\n","                      f_min=0.0, \\\n","                      f_max=None, \\\n","                      pad=0, \\\n","                      n_mels=128, \\\n","                      \\\n","                      )(fs)(sound) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W_B1py3PhQF4","colab_type":"code","colab":{}},"source":["a = MelSpectrogram(fs)(sound) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IKE7hOtdhhXg","colab_type":"code","colab":{}},"source":["sound, _ = musicnet_dataset['1727']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_W25RQGJhmfl","colab_type":"code","colab":{}},"source":["from torch.utils.data import Dataset, DataLoader\n","\n","class MusicnetComposers(Dataset):\n","    def __init__(self, csv_path, dataset_path, composers, split_duration, n_samples, fs):\n","        musicnet_metadata = pd.read_csv(csv_path)\n","        with open(dataset_path, 'rb') as npz:\n","          musicnet_dataset = np.load(dataset_path, encoding = 'latin1', allow_pickle=True)\n","        self.dataset = np.zeros((len(composers)*n_samples, fs*split_duration))\n","        self.labels = np.zeros(len(composers)*n_samples, dtype=int)\n","        count = 0\n","        for composer in composers:\n","          composerMetadata = musicnet_metadata.loc[musicnet_metadata.composer == composer]\n","          composer_data = []\n","          for row in composerMetadata.itertuples():\n","            print(row.Index)\n","            id = str(row.id)\n","            duration = row.seconds\n","            sound, _ = musicnet_dataset[id]\n","            n_splits = np.floor(duration/split_duration).astype('int64')\n","            for i in range(n_splits):\n","              start = i*fs*split_duration\n","              end = (i+1)*fs*split_duration\n","              split = sound[start:end]\n","              composer_data.append(split)\n","            if len(composer_data) >= n_samples:\n","              break\n","          index = np.random.randint(low=0, high=len(composer_data), size=n_samples)\n","          composer_data = [composer_data[i] for i in index]\n","          print(len(composer_data))\n","          print(np.array(composer_data).shape)\n","          print(self.dataset[count*n_samples:(count+1)*n_samples].shape)\n","\n","          self.dataset[count*n_samples:(count+1)*n_samples] = np.array(composer_data)\n","          self.labels[count*n_samples:(count+1)*n_samples] = count\n","          count += 1\n","          if len(composer_data) >= n_samples:\n","            break\n","\n","        self.composers = composers\n","        self.split_duration = split_duration\n","        self.n_samples = n_samples\n","        self.fs = fs\n","        \n","    def __getitem__(self, index):\n","\n","        sound = torch.Tensor(self.dataset[index]).reshape(1,-1)\n","        spectogram = MelSpectrogram(sample_rate=self.fs, \\\n","                                     n_fft=2048, \\\n","                                     win_length=None, \\\n","                                     hop_length=512, \\\n","                                     f_min=0.0, \\\n","                                     f_max=None, \\\n","                                     pad=0, \\\n","                                     n_mels=128, \\\n","                                     \\\n","                                     )(sound)\n","      \n","        return self.dataset[index], self.labels[index]\n","    \n","    def __len__(self):\n","        return len(self.labels)\n","\n","    \n","csv_path = 'musicnet_metadata.csv'\n","dataset_path = 'musicnet.npz'\n","fs = 44100\n","composers = ['Schubert', 'Beethoven', 'Brahms', 'Mozart', 'Bach']\n","split_duration = 20\n","n_samples = 100\n","train_set = MusicnetComposers(csv_path, dataset_path, composers, split_duration, n_samples, fs)\n","print(\"Train set size: \" + str(len(train_set)))\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GPBd4ISO3nzq","colab_type":"code","colab":{}},"source":["import torch\n","from torchaudio.transforms import MelSpectrogram\n","train_set[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RbfPuckYsnCB","colab_type":"code","colab":{}},"source":["#train_set[2]\n","t = torch.Tensor(sound)\n","spec = MelSpectrogram(sample_rate=fs, n_fft=2048, hop_length=512)(t.reshape(1,-1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ptrvlOa3zJaV","colab_type":"code","colab":{}},"source":["fig = plt.figure(figsize=(10,4))\n","plt.pcolormesh(np.log(spec[0].numpy()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QlygBtTE0EAH","colab_type":"code","colab":{}},"source":["      spectogram = librosa.feature.melspectrogram(y=sound, \\\n","                                        sr=fs, \\\n","                  )\n","plt.figure(figsize=(10, 4))\n","S_dB = librosa.power_to_db(spec[0].numpy(), ref=np.max)\n","librosa.display.specshow(S_dB, x_axis='time', y_axis='mel', sr=fs)\n","plt.colorbar(format='%+2.0f dB')\n","plt.title('Mel-frequency spectrogram')\n","plt.tight_layout()\n","plt.show()\n","plt.axis('off')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q1OmkWQLrulp","colab_type":"code","colab":{}},"source":["\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size = 128, shuffle = True)\n","#test_loader = torch.utils.data.DataLoader(test_set, batch_size = 128, shuffle = True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SR1bg7X62jew","colab_type":"code","colab":{}},"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv1d(1, 128, 80, 4)\n","        self.bn1 = nn.BatchNorm1d(128)\n","        self.pool1 = nn.MaxPool1d(4)\n","        self.conv2 = nn.Conv1d(128, 128, 3)\n","        self.bn2 = nn.BatchNorm1d(128)\n","        self.pool2 = nn.MaxPool1d(4)\n","        self.conv3 = nn.Conv1d(128, 256, 3)\n","        self.bn3 = nn.BatchNorm1d(256)\n","        self.pool3 = nn.MaxPool1d(4)\n","        self.conv4 = nn.Conv1d(256, 512, 3)\n","        self.bn4 = nn.BatchNorm1d(512)\n","        self.pool4 = nn.MaxPool1d(4)\n","        self.avgPool = nn.AvgPool1d(30)\n","        self.fc1 = nn.Linear(512, 10)\n","        \n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = F.relu(self.bn1(x))\n","        x = self.pool1(x)\n","        x = self.conv2(x)\n","        x = F.relu(self.bn2(x))\n","        x = self.pool2(x)\n","        x = self.conv3(x)\n","        x = F.relu(self.bn3(x))\n","        x = self.pool3(x)\n","        x = self.conv4(x)\n","        x = F.relu(self.bn4(x))\n","        x = self.pool4(x)\n","        x = self.avgPool(x)\n","        x = x.permute(0, 2, 1) #change the 512x1 to 1x512\n","        x = self.fc1(x)\n","        return F.log_softmax(x, dim = 2)\n","\n","model = Net()\n","model.to(device)\n","print(model)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.01, weight_decay = 0.0001)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 20, gamma = 0.1)\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F6J4KIfq3GdX","colab_type":"code","colab":{}},"source":["def train(model, epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        data = data.to(device)\n","        target = target.to(device)\n","        data = data.requires_grad_() #set requires_grad to True for training\n","        output = model(data)\n","        output = output.permute(1, 0, 2) #original output dimensions are batchSizex1x10 \n","        loss = F.nll_loss(output[0], target) #the loss functions expects a batchSizex10 input\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % log_interval == 0: #print training stats\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wbaXgL_b3fKg","colab_type":"code","colab":{}},"source":["train(model,1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ujq5J-EN3glZ","colab_type":"code","colab":{}},"source":["!wget https://homes.cs.washington.edu/~thickstn/media/musicnet.tar.gz"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oRAI9cFYTrNK","colab_type":"code","colab":{}},"source":["!\ttar xvzf musicnet.tar.gz"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"whmFzebFU9mp","colab_type":"code","colab":{}},"source":["a = np.zeros((5*300, 44100*20))\n","b = np.zeros(5*300, dtype=int)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SftQQ66pXTvY","colab_type":"code","colab":{}},"source":["from torch.utils.data import Dataset, DataLoader\n","\n","class MusicnetComposers2(Dataset):\n","    def __init__(self, csv_path, dataset_path, composers, split_duration, n_samples, fs):\n","        musicnet_metadata = pd.read_csv(csv_path)\n","        self.dataset = np.zeros((len(composers)*n_samples, fs*split_duration))\n","        self.labels = np.zeros(len(composers)*n_samples, dtype=int)\n","        count = 0\n","        for composer in composers:\n","          composerMetadata = musicnet_metadata.loc[musicnet_metadata.composer == composer]\n","          composer_data = []\n","          for row in composerMetadata.itertuples():\n","            print(row.Index)\n","            id = str(row.id)\n","            duration = row.seconds\n","            file_\n","            sound, _ = torchaudio.load(filepath, normalization=False)\n","            n_splits = np.floor(duration/split_duration).astype('int64')\n","            for i in range(n_splits):\n","              start = i*fs*split_duration\n","              end = (i+1)*fs*split_duration\n","              split = sound[start:end]\n","              composer_data.append(split)\n","            if len(composer_data) >= n_samples:\n","              break\n","          index = np.random.randint(low=0, high=len(composer_data), size=n_samples)\n","          composer_data = [composer_data[i] for i in index]\n","          print(len(composer_data))\n","          print(np.array(composer_data).shape)\n","          print(self.dataset[count*n_samples:(count+1)*n_samples].shape)\n","\n","          self.dataset[count*n_samples:(count+1)*n_samples] = np.array(composer_data)\n","          self.labels[count*n_samples:(count+1)*n_samples] = count\n","          count += 1\n","          if len(composer_data) >= n_samples:\n","            break\n","\n","        self.composers = composers\n","        self.split_duration = split_duration\n","        self.n_samples = n_samples\n","        self.fs = fs\n","        \n","    def __getitem__(self, index):\n","\n","        sound = torch.Tensor(self.dataset[index]).reshape(1,-1)\n","        spectogram = MelSpectrogram(sample_rate=self.fs, \\\n","                                     n_fft=2048, \\\n","                                     win_length=None, \\\n","                                     hop_length=512, \\\n","                                     f_min=0.0, \\\n","                                     f_max=None, \\\n","                                     pad=0, \\\n","                                     n_mels=128, \\\n","                                     \\\n","                                     )(sound)\n","      \n","        return self.dataset[index], self.labels[index]\n","    \n","    def __len__(self):\n","        return len(self.labels)\n","\n","    \n","csv_path = 'musicnet_metadata.csv'\n","dataset_path = 'musicnet.npz'\n","fs = 44100\n","composers = ['Schubert', 'Beethoven', 'Brahms', 'Mozart', 'Bach']\n","split_duration = 20\n","n_samples = 100\n","train_set = MusicnetComposers(csv_path, dataset_path, composers, split_duration, n_samples, fs)\n","print(\"Train set size: \" + str(len(train_set)))\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EYKyawFqZVPF","colab_type":"code","colab":{}},"source":["!wget https://homes.cs.washington.edu/~thickstn/media/musicnet_metadata.csv\n","musicnet_metadata = pd.read_csv('musicnet_metadata.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mEKRc8LaZcYM","colab_type":"code","colab":{}},"source":["musicnet_metadata"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gdXvB5UDZd7j","colab_type":"code","colab":{}},"source":["a = musicnet_metadata.loc[musicnet_metadata.id == 1727]\n","a"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SMKGNmyHk7H9","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"hIdPu2EYaLOS","colab_type":"code","colab":{}},"source":["a = np.zeros((5*300, 44100*20))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tg6IOPQHk6uX","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"0AwA6RXek1b-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}